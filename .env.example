
# GLOBAL ENV

ENV=local                        
SERVICE_NAME=risk-api            
LOG_LEVEL=INFO                   
JSON_LOGS=true

# Used for request correlation across logs and traces
REQUEST_ID_HEADER=x-request-id


# API SETTINGS

API_HOST=0.0.0.0
API_PORT=8080
API_WORKERS=2
CORS_ALLOW_ORIGINS=              


# DATABASE (RDS POSTGRES)

DB_HOST=localhost
DB_PORT=5432
DB_NAME=risk_intel
DB_USER=risk_admin
DB_PASSWORD=change_me
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_RECYCLE_SECONDS=1800


# OBJECT STORAGE (S3)

AWS_REGION=eu-west-2
S3_BUCKET_RAW=ai-risk-raw
S3_BUCKET_CURATED=ai-risk-curated
S3_BUCKET_ARTIFACTS=ai-risk-artifacts
S3_BUCKET_EVAL=ai-risk-eval
S3_BUCKET_DRIFT=ai-risk-drift


# OPENSEARCH (EVIDENCE + RETRIEVAL INDEX)

OPENSEARCH_HOST=http://localhost:9200
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=admin
OPENSEARCH_INDEX_EVIDENCE=risk_evidence
OPENSEARCH_INDEX_EMBEDDINGS=risk_embeddings


# MODEL REGISTRY (ABSTRACTION BACKED BY S3 + METADATA STORE)

MODEL_REGISTRY_PROVIDER=s3        # s3 (backing store for artifacts)
MODEL_REGISTRY_BUCKET=ai-risk-artifacts
MODEL_REGISTRY_PREFIX=model-registry
MODEL_REGISTRY_METADATA_TABLE=risk_model_registry   # for prod: DynamoDB; local: Postgres table
MODEL_REGISTRY_ALLOW_UNREGISTERED=false


# FRAUD / ANOMALY MODEL SETTINGS

FRAUD_MODEL_NAME=fraud_iforest_v1
FRAUD_MODEL_STAGE=prod            # dev|staging|prod
FRAUD_SCORE_THRESHOLD=0.85
FRAUD_MAX_LOOKBACK_DAYS=30
FRAUD_VELOCITY_WINDOWS=5m,1h,24h


# CONDUCT / COMPLIANCE MODEL SETTINGS

CONDUCT_MODEL_NAME=conduct_hybrid_v1
CONDUCT_MODEL_STAGE=prod
CONDUCT_SCORE_THRESHOLD=0.70


# NLP / EMBEDDINGS (SINGLE IMPLEMENTATION)

EMBEDDINGS_PROVIDER=sentence_transformers  # sentence_transformers|openai
EMBEDDINGS_MODEL=all-MiniLM-L6-v2
EMBEDDINGS_BATCH_SIZE=64
EMBEDDINGS_CACHE_TTL_SECONDS=3600


# DRIFT DETECTION (STRUCTURED + EMBEDDING DRIFT)

DRIFT_ENABLED=true
DRIFT_STRUCTURED_METHOD=psi                 # psi
DRIFT_STRUCTURED_ALERT_THRESHOLD=0.2
DRIFT_EMBED_METHOD=cosine_centroid_shift    # cosine_centroid_shift|mmd
DRIFT_EMBED_ALERT_THRESHOLD=0.10
DRIFT_SNAPSHOT_INTERVAL_MINUTES=60


# LLM GATEWAY (SINGLE CLIENT + VERSIONED PROMPTS)

LLM_PROVIDER=openai               # openai|gemini|claude (abstracted in code)
LLM_TIMEOUT_SECONDS=20
LLM_MAX_RETRIES=2
LLM_RETRY_BACKOFF_SECONDS=1.5
LLM_REQUEST_LOGGING=true
LLM_PROMPT_VERSION=2026-01-03     # prompt bundle version key

# OpenAI (used ONLY via LLM gateway)
OPENAI_API_KEY=change_me
OPENAI_MODEL=gpt-4.1-mini         # example; actual model selection is policy-controlled in gateway


OPENAI_EMBEDDING_MODEL=text-embedding-3-large


# OBSERVABILITY (MANDATORY)

OTEL_ENABLED=true
OTEL_SERVICE_NAME=ai-risk-intel
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_EXPORTER_OTLP_PROTOCOL=grpc
OTEL_TRACES_SAMPLER=parentbased_traceidratio
OTEL_TRACES_SAMPLER_ARG=0.1

# Metrics endpoint (Prometheus scraping)
METRICS_ENABLED=true
METRICS_PORT=9090


# SECURITY / AUDIT

AUDIT_LOGGING_ENABLED=true
AUDIT_HASH_CHAIN_ENABLED=true          # immutable audit chain for decisions
PII_REDACTION_ENABLED=true
PII_REDACTION_MODE=strict              # strict|moderate


# WORKER / QUEUE (OPTIONAL BUT CLOUD-REALISTIC)

QUEUE_PROVIDER=sqs                     # sqs|none
SQS_QUEUE_URL=
WORKER_MAX_CONCURRENCY=4
WORKER_POLL_SECONDS=2


# FEATURE STORE (INTERFACE ONLY; BACKED BY POSTGRES FOR ONLINE)

FEATURE_STORE_PROVIDER=postgres
FEATURE_STORE_SCHEMA=feature_store
FEATURE_STORE_WRITE_MODE=upsert